{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeKdy9BB5VNhyYd6qSvq3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamT2023/Flooding/blob/main/Averaging_columns%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "8bpHLjGojMTD",
        "outputId": "215ffe39-87e1-40a1-99be-17fcf259a981"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8959cf4adf62>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data.csv\"\u001b[0m  \u001b[0;31m# Replace with your actual file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdate_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"date\"\u001b[0m  \u001b[0;31m# Replace with the actual column name containing dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_rows_by_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-8959cf4adf62>\u001b[0m in \u001b[0;36maverage_rows_by_date\u001b[0;34m(file_path, date_column)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Ensure the date column is in datetime format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Group by the date column and compute the mean for each group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def average_rows_by_date(file_path, date_column):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv('/content/mig2.csv')\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "\n",
        "    # Group by the date column and compute the mean for each group\n",
        "    averaged_df = df.groupby(date_column).mean().reset_index()\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"data.csv\"  # Replace with your actual file path\n",
        "    date_column = \"date\"  # Replace with the actual column name containing dates\n",
        "    result = average_rows_by_date(file_path, date_column)\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def average_rows_by_date(\"E:\\PhD_Project_VUB\\Weather_Data\\Data - Lake Victoria Basin\\Rwambwa Discharge\\mig2.csv\", Date):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv('/content/mig2.csv')\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
        "\n",
        "    # Drop rows where date conversion failed\n",
        "    df = df.dropna(subset=[date_column])\n",
        "\n",
        "    # Group by the date column and compute the mean for each group\n",
        "    averaged_df = df.groupby(date_column, as_index=False).mean()\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"data.csv\"  # Replace with your actual file path\n",
        "    date_column = \"date\"  # Replace with the actual column name containing dates\n",
        "    result = average_rows_by_date(file_path, date_column)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "I-_nKZqklIe9",
        "outputId": "ba118c40-ab7a-4baf-b469-4a5863ebf0ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-4-ed716f22e1d0>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-ed716f22e1d0>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    def average_rows_by_date(\"E:\\PhD_Project_VUB\\Weather_Data\\Data - Lake Victoria Basin\\Rwambwa Discharge\\mig2.csv\", Date):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "import pandas as pd\n",
        "\n",
        "def average_rows_by_date(file_path, date_column):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(file_path) # Use the file_path argument\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "\n",
        "    # Group by the date column and compute the mean for each group\n",
        "    averaged_df = df.groupby(date_column).mean().reset_index()\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/mig2.csv\"  # Correct file path\n",
        "    date_column = \"date\"  # Replace with the actual column name containing dates\n",
        "    result = average_rows_by_date(file_path, date_column)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "zH6AZ1XWkbJS",
        "outputId": "79f62ff1-776e-4c46-c99e-0c9e2d49b2d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c160a6bd5db1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/mig2.csv\"\u001b[0m  \u001b[0;31m# Correct file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdate_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"date\"\u001b[0m  \u001b[0;31m# Replace with the actual column name containing dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_rows_by_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c160a6bd5db1>\u001b[0m in \u001b[0;36maverage_rows_by_date\u001b[0;34m(file_path, date_column)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Ensure the date column is in datetime format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Group by the date column and compute the mean for each group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def average_rows_by_date(file_path, date_column):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(file_path) # Use the file_path argument\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    # Replace 'date' with the actual name of your date column if it's different\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
        "\n",
        "    # Handle potential errors during date conversion\n",
        "    df = df.dropna(subset=[date_column])\n",
        "\n",
        "    # Group by the date column and compute the mean for each group\n",
        "    averaged_df = df.groupby(date_column).mean().reset_index()\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/mig2.csv\"  # Correct file path\n",
        "    date_column = \"Date\"  # Replace 'Date' with the actual column name if needed\n",
        "    result = average_rows_by_date(file_path, date_column)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed1FQ3UnmFB8",
        "outputId": "ed177323-fdb8-4013-e665-b4e4c55796a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Date  1KB05-Gucha Migori [m^3/s]\n",
            "0     1969-03-01 09:00:00                   83.463538\n",
            "1     1969-03-01 16:00:00                   76.927892\n",
            "2     1969-03-02 09:00:00                   69.012640\n",
            "3     1969-03-02 16:00:00                   69.012640\n",
            "4     1969-03-03 09:00:00                   59.407718\n",
            "...                   ...                         ...\n",
            "28617 2021-04-28 20:00:00                  120.558777\n",
            "28618 2021-04-29 08:00:00                   40.398594\n",
            "28619 2021-04-29 20:00:00                   41.268154\n",
            "28620 2021-04-30 08:00:00                   94.168981\n",
            "28621 2021-04-30 20:00:00                   79.629435\n",
            "\n",
            "[28622 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def average_selected_column_by_date(file_path, date_column, target_column):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv('/content/mig2.csv')\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    # The error was here, the column is named 'Date', not 'date'\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
        "\n",
        "    # Drop rows where date conversion failed\n",
        "    df = df.dropna(subset=[date_column])\n",
        "\n",
        "    # Group by the date column and compute the mean for the target column\n",
        "    averaged_df = df.groupby(date_column, as_index=False)[target_column].mean()\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"data.csv\"  # Replace with your actual file path\n",
        "    # Change 'date' to 'Date' to match the actual column name in your CSV\n",
        "    date_column = \"Date\"\n",
        "    target_column = \"1KB05-Gucha Migori [m^3/s]\"  # Column to be averaged\n",
        "    result = average_selected_column_by_date(file_path, date_column, target_column)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDGt4qPaoz06",
        "outputId": "6f572d8a-955f-4c91-b3c8-8952dd40a29e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Date  1KB05-Gucha Migori [m^3/s]\n",
            "0     1969-03-01 09:00:00                   83.463538\n",
            "1     1969-03-01 16:00:00                   76.927892\n",
            "2     1969-03-02 09:00:00                   69.012640\n",
            "3     1969-03-02 16:00:00                   69.012640\n",
            "4     1969-03-03 09:00:00                   59.407718\n",
            "...                   ...                         ...\n",
            "28617 2021-04-28 20:00:00                  120.558777\n",
            "28618 2021-04-29 08:00:00                   40.398594\n",
            "28619 2021-04-29 20:00:00                   41.268154\n",
            "28620 2021-04-30 08:00:00                   94.168981\n",
            "28621 2021-04-30 20:00:00                   79.629435\n",
            "\n",
            "[28622 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def average_selected_column_by_year(file_path, date_column, target_column):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
        "\n",
        "    # Drop rows where date conversion failed\n",
        "    df = df.dropna(subset=[date_column])\n",
        "\n",
        "    # Extract the year from the Date column\n",
        "    df['Year'] = df[date_column].dt.year\n",
        "\n",
        "    # Group by the year and compute the mean for the target column\n",
        "    averaged_df = df.groupby('Year', as_index=False)[target_column].mean()\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/mig2.csv\"  # Replace with your actual file path\n",
        "    date_column = \"Date\"  # Replace 'Date' with the actual column name if needed\n",
        "    target_column = \"1KB05-Gucha Migori [m^3/s]\"  # Column to be averaged\n",
        "    result = average_selected_column_by_year(file_path, date_column, target_column)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZlsBA4LplRa",
        "outputId": "ce70d9c4-af28-49e1-dfc9-a5a1da3e90fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Year  1KB05-Gucha Migori [m^3/s]\n",
            "0   1969                   26.348134\n",
            "1   1970                   52.768080\n",
            "2   1971                   32.998174\n",
            "3   1972                   39.325796\n",
            "4   1973                   46.575879\n",
            "5   1974                   48.689654\n",
            "6   1975                   33.321112\n",
            "7   1976                   37.490904\n",
            "8   1977                   71.396123\n",
            "9   1978                   68.329330\n",
            "10  1979                   45.278382\n",
            "11  1980                   34.506072\n",
            "12  1981                   37.627358\n",
            "13  1982                   59.892686\n",
            "14  1983                   29.923794\n",
            "15  1984                   15.114191\n",
            "16  1985                   37.828399\n",
            "17  1986                   32.562340\n",
            "18  1987                   50.829040\n",
            "19  1988                   48.858633\n",
            "20  1989                   43.525250\n",
            "21  1990                   51.745065\n",
            "22  1991                   34.280447\n",
            "23  1992                   35.522817\n",
            "24  1993                   32.687033\n",
            "25  1994                   17.700898\n",
            "26  2003                   94.611336\n",
            "27  2004                  154.204529\n",
            "28  2005                   86.148088\n",
            "29  2006                   49.457940\n",
            "30  2007                   34.920596\n",
            "31  2008                   64.068143\n",
            "32  2009                  111.762991\n",
            "33  2010                   59.376779\n",
            "34  2011                   44.533178\n",
            "35  2012                   39.558775\n",
            "36  2013                   75.431950\n",
            "37  2014                         NaN\n",
            "38  2015                   58.133578\n",
            "39  2019                   12.134794\n",
            "40  2020                   31.941255\n",
            "41  2021                   48.962358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def average_selected_column_by_date(file_path, date_column, target_column):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv('/content/mig2.csv')\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
        "\n",
        "    # Drop rows where date conversion failed\n",
        "    df = df.dropna(subset=[date_column])\n",
        "\n",
        "    # Group by the date column and compute the mean for the target column\n",
        "    averaged_df = df.groupby(date_column, as_index=False)[target_column].mean()\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/mig2.csv\"  # Replace with your actual file path\n",
        "    date_column = \"Date\"  # Replace 'Date' with the actual column name if needed\n",
        "    target_column = \"1KB05-Gucha Migori [m^3/s]\"  # Column to be averaged\n",
        "    result = average_selected_column_by_date(file_path, date_column, target_column)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhlsy9Emq8ZM",
        "outputId": "e75d1aff-a7df-4a56-a37a-34cfc0a8f763"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Date  1KB05-Gucha Migori [m^3/s]\n",
            "0     1969-03-01 09:00:00                   83.463538\n",
            "1     1969-03-01 16:00:00                   76.927892\n",
            "2     1969-03-02 09:00:00                   69.012640\n",
            "3     1969-03-02 16:00:00                   69.012640\n",
            "4     1969-03-03 09:00:00                   59.407718\n",
            "...                   ...                         ...\n",
            "28617 2021-04-28 20:00:00                  120.558777\n",
            "28618 2021-04-29 08:00:00                   40.398594\n",
            "28619 2021-04-29 20:00:00                   41.268154\n",
            "28620 2021-04-30 08:00:00                   94.168981\n",
            "28621 2021-04-30 20:00:00                   79.629435\n",
            "\n",
            "[28622 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_average_by_date(file_path, date_column, target_column):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv('/content/mig2.csv')\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
        "\n",
        "    # Drop rows where date conversion failed\n",
        "    df = df.dropna(subset=[date_column])\n",
        "\n",
        "    # Extract only the date part (removing time) for grouping\n",
        "    df[\"date_only\"] = df[date_column].dt.date\n",
        "\n",
        "    # Group by the date-only column and compute the mean for the target column\n",
        "    averaged_df = df.groupby(\"date_only\", as_index=False)[target_column].mean()\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"data.csv\"  # Replace with your actual file path\n",
        "    date_column = \"Date\"  # Replace with the actual column name containing dates\n",
        "    target_column = \"1KB05-Gucha Migori [m^3/s]\"  # Column to be averaged\n",
        "    result = get_average_by_date(file_path, date_column, target_column)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-m51prerxit",
        "outputId": "195faf1a-1106-41b7-845e-f5faabca6227"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        date_only  1KB05-Gucha Migori [m^3/s]\n",
            "0      1969-03-01                   80.195715\n",
            "1      1969-03-02                   69.012640\n",
            "2      1969-03-03                   57.941754\n",
            "3      1969-03-04                   51.703579\n",
            "4      1969-03-05                   47.989989\n",
            "...           ...                         ...\n",
            "14849  2021-04-26                  151.800365\n",
            "14850  2021-04-27                  133.463807\n",
            "14851  2021-04-28                  150.728844\n",
            "14852  2021-04-29                   40.833374\n",
            "14853  2021-04-30                   86.899208\n",
            "\n",
            "[14854 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_average_by_date(file_path, date_column, target_column, output_file):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv('/content/mig2.csv')\n",
        "\n",
        "    # Ensure the date column is in datetime format\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
        "\n",
        "    # Drop rows where date conversion failed\n",
        "    df = df.dropna(subset=[date_column])\n",
        "\n",
        "    # Extract only the date part (removing time) for grouping\n",
        "    df[\"date_only\"] = df[date_column].dt.date\n",
        "\n",
        "    # Group by the date-only column and compute the mean for the target column\n",
        "    averaged_df = df.groupby(\"date_only\", as_index=False)[target_column].mean()\n",
        "\n",
        "    # Save the result to a CSV file\n",
        "    averaged_df.to_csv(output_file, index=False)\n",
        "\n",
        "    return averaged_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"data.csv\"  # Replace with your actual file path\n",
        "    date_column = \"Date\"  # Replace with the actual column name containing dates\n",
        "    target_column = \"1KB05-Gucha Migori [m^3/s]\"  # Column to be averaged\n",
        "    output_file = \"averaged_data.csv\"  # Output file path\n",
        "    result = get_average_by_date(file_path, date_column, target_column, output_file)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW5m84r3skHh",
        "outputId": "96127876-695f-48a9-cdee-af942abb3963"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        date_only  1KB05-Gucha Migori [m^3/s]\n",
            "0      1969-03-01                   80.195715\n",
            "1      1969-03-02                   69.012640\n",
            "2      1969-03-03                   57.941754\n",
            "3      1969-03-04                   51.703579\n",
            "4      1969-03-05                   47.989989\n",
            "...           ...                         ...\n",
            "14849  2021-04-26                  151.800365\n",
            "14850  2021-04-27                  133.463807\n",
            "14851  2021-04-28                  150.728844\n",
            "14852  2021-04-29                   40.833374\n",
            "14853  2021-04-30                   86.899208\n",
            "\n",
            "[14854 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}